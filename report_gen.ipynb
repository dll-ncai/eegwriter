{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cereprocess.datasets.pipeline import general_pipeline, neurotransformer_pipeline, resample\n",
    "from cereprocess.datasets.channels import NEUROTRANSFORMER_CHANNELS\n",
    "from models.neurogate import NeuroGate\n",
    "from models.neurotransformer import Neurotransformer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import mne\n",
    "import numpy as np\n",
    "import ollama\n",
    "import gc\n",
    "from pdr import PDREstimator\n",
    "\n",
    "CHANNEL_REGIONS = {\n",
    "    \"Frontal\": [\"FP1\", \"FP2\", \"F3\", \"F4\", \"FZ\"],\n",
    "    \"Left Temporal\": [\"F7\", \"T3\", \"T5\"],\n",
    "    \"Right Temporal\": [\"F8\", \"T4\", \"T6\"],\n",
    "    \"Central\": [\"C3\", \"C4\", \"CZ\"],\n",
    "    \"Parietal\": [\"P3\", \"P4\", \"PZ\"],\n",
    "    \"Occipital\": [\"O1\", \"O2\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "neurogate = NeuroGate().to(device)\n",
    "neurotransformer = Neurotransformer().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights\n",
    "neurogate.load_state_dict(torch.load('model_weights/neurogate_wgts.pt'))\n",
    "neurogate.eval()\n",
    "neurotransformer.load_state_dict(torch.load('model_weights/neurotransformer_wgts.pth'))\n",
    "neurotransformer.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Pipelines\n",
    "neurogate_pl = general_pipeline('NMT')\n",
    "neurotransformer_pl = neurotransformer_pipeline('NMT')\n",
    "pdr_pl = resample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PDREstimator\n",
    "o1_idx = NEUROTRANSFORMER_CHANNELS.index(\"O1\")\n",
    "o2_idx = NEUROTRANSFORMER_CHANNELS.index(\"O2\")\n",
    "estimator = PDREstimator(200, o1_idx, o2_idx, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clinical_adjective(percentage):\n",
    "    \"\"\"\n",
    "    Returns clinical quantification terms based on ACNS 2021 Guidelines.\n",
    "    Reference: Hirsch LJ, et al. J Clin Neurophysiol. 2021.\n",
    "    \"\"\"\n",
    "    if percentage < 15.0:\n",
    "        return \"Occasional\"  # Shifted up (was 1-10%)\n",
    "    elif percentage < 50.0:\n",
    "        return \"Frequent\"    # (15-49%)\n",
    "    elif percentage < 90.0:\n",
    "        return \"Abundant\"    # (50-89%)\n",
    "    else:\n",
    "        return \"Continuous\"  # (>= 90%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ab_prob(mne_data):\n",
    "    # Pass through neurogate\n",
    "    processed_data = neurogate_pl.apply(mne_data)\n",
    "    data = processed_data.get_data()\n",
    "    data = data[None, :, :]  \n",
    "    data = torch.from_numpy(data).float().to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = neurogate(data)\n",
    "\n",
    "    ab_prob = list(F.softmax(outputs).cpu().numpy().reshape(-1,))[1] * 100\n",
    "    return ab_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region_report(mne_data):\n",
    "    all_events = np.array([\"normal wave\", \"spike and sharp wave\", \"slow wave\"])\n",
    "\n",
    "    processed_data = neurotransformer_pl.apply(mne_data)\n",
    "    data = processed_data.get_data()\n",
    "\n",
    "    result_events = {}\n",
    "\n",
    "    for i, ch_name in enumerate(NEUROTRANSFORMER_CHANNELS):\n",
    "        ch_data = data[:, i:i+1, :]\n",
    "        ch_data = torch.from_numpy(ch_data).float().to(device)\n",
    "        outputs=None\n",
    "        with torch.no_grad():\n",
    "            outputs = neurotransformer(ch_data)\n",
    "        outputs = outputs.cpu().numpy()\n",
    "        outputs = outputs.argmax(axis=1)\n",
    "        events = list(all_events[outputs])\n",
    "        result_events[ch_name] = events\n",
    "\n",
    "    region_report = {}\n",
    "\n",
    "    for region_name, channels in CHANNEL_REGIONS.items():\n",
    "        total_windows = 0\n",
    "        spike_count = 0\n",
    "        slow_count = 0\n",
    "        \n",
    "        for ch in channels:\n",
    "            events = result_events[ch]\n",
    "            total_windows += len(events)\n",
    "            spike_count += events.count(\"spike and sharp wave\")\n",
    "            slow_count += events.count(\"slow wave\")\n",
    "\n",
    "        # Calculate Percentages\n",
    "        spike_pct = (spike_count / total_windows) * 100\n",
    "        slow_pct = (slow_count / total_windows) * 100\n",
    "        \n",
    "        # Generate Clinical Descriptors\n",
    "        findings = []\n",
    "\n",
    "        if spike_pct >= 5.0: # Threshold to report it\n",
    "            adj = get_clinical_adjective(spike_pct)\n",
    "            findings.append(f\"{adj} epileptiform discharges\")\n",
    "            \n",
    "        # 2. Analyze Slowing\n",
    "        if slow_pct >= 5.0:\n",
    "            adj = get_clinical_adjective(slow_pct)\n",
    "            findings.append(f\"{adj} slowing\")\n",
    "\n",
    "        if not findings:\n",
    "            description = \"Normal activity.\"\n",
    "        else:\n",
    "            description = \", \".join(findings) + \".\"\n",
    "\n",
    "        region_report[region_name] = {\n",
    "            \"description\": description,\n",
    "            \"stats\": {\n",
    "                \"spike_pct\": spike_pct,\n",
    "                \"slow_pct\": slow_pct\n",
    "            }\n",
    "        }\n",
    "    return region_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdr(mne_data):\n",
    "    # Get PDR\n",
    "    processed_data = pdr_pl.apply(mne_data)\n",
    "    data = processed_data.get_data()\n",
    "    pdr_res = estimator.fit(data)\n",
    "\n",
    "    # Format PDR for the report\n",
    "    if pdr_res['pdr_o1'] and pdr_res['pdr_o2']:\n",
    "        avg_pdr = (pdr_res['pdr_o1'] + pdr_res['pdr_o2']) / 2\n",
    "        pdr_text = f\"{avg_pdr:.1f} Hz\"\n",
    "    elif pdr_res['pdr_o1'] or pdr_res['pdr_o2']:\n",
    "        val = pdr_res['pdr_o1'] or pdr_res['pdr_o2']\n",
    "        pdr_text = f\"{val:.1f} Hz\"\n",
    "    else:\n",
    "        pdr_text = \"Not well-formed\"\n",
    "\n",
    "    return pdr_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on each file\n",
    "EDF_ROOT = \"/media/tukl/ee279b7d-bb8a-4a20-8bf9-90b2c542efcc/EEG Datasets/nmt_4k_f/edf\"\n",
    "REPORTS = \"reports_gen\"\n",
    "sub_folders = ['normal', 'abnormal']\n",
    "\n",
    "for folder in sub_folders:\n",
    "    folder_path = os.path.join(EDF_ROOT, folder)\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        if filename.replace('.edf', '.txt') in os.listdir(os.path.join(REPORTS, folder)):\n",
    "            print(f\"Report already exists for {filename}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            mne_data = mne.io.read_raw_edf(file_path, preload=True)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "        ab_prob = get_ab_prob(mne_data)\n",
    "        print(ab_prob)\n",
    "\n",
    "        region_report = get_region_report(mne_data)\n",
    "        for region in CHANNEL_REGIONS.keys():\n",
    "            print(region_report[region])\n",
    "\n",
    "        pdr_text = get_pdr(mne_data)\n",
    "        print(pdr_text)\n",
    "\n",
    "        # Construct the Prompt\n",
    "        prompt_content = f\"\"\"\n",
    "        PATIENT STATISTICS:\n",
    "        - Global Abnormality Probability: {ab_prob:.1f}% (If >50%, consider Abnormal)\n",
    "        - Posterior Dominant Rhythm: {pdr_text}\n",
    "        \n",
    "        REGIONAL ANALYSIS:\n",
    "        \"\"\"\n",
    "        for region, desc in region_report.items():\n",
    "            prompt_content += f\"- {region}: {desc}\\n\"\n",
    "\n",
    "        system_instruction = \"\"\"\n",
    "        You are a clinical neurologist. Write a standard EEG report based strictly on the provided statistics.\n",
    "        \n",
    "        Format Requirements:\n",
    "        1. Use exactly two sections: \"FACTUAL REPORT\" and \"IMPRESSION\".\n",
    "        2. In FACTUAL REPORT, describe the background (PDR) first, then regional findings.\n",
    "        3. In IMPRESSION, state \"Normal EEG\" or \"Abnormal EEG\" followed by a summary sentence.\n",
    "        4. Absolutely do not mention percentages in the final text; use clinical terms (Frequent, Occasional).\n",
    "        5. Write each section as a paragraph.\n",
    "        6. Do not use points.\n",
    "        7. Do not describe each and every region separately.\n",
    "        8. Do not assume any information on your own.\n",
    "\n",
    "        EXAMPLES:\n",
    "        Normal Report:\n",
    "        FACTUAL REPORT: Background rhythm shows alpha waveform seen around 8 Hz which is appropriate for age. Photic stimulation and HV not performed due to the state of patient. Intermittent EMG artifacts were seen. Stage II sleep was not achieved.\n",
    "\n",
    "        IMPRESSION: This EEG showed very mild encephalopathy and there is no element of non convulsive status. Kindly correlate with clinical picture.\n",
    "\n",
    "        Abnormal Report:\n",
    "        FACTUAL REPORT: Background rhythm during awake stage shows well-organized, welldeveloped, average voltage 10 hertz alpha activity in the posterior regions which is appropriate for age. It blocks with eye opening and it is bilaterally synchronous and symmetrical. Beta activity in the frontal or central areas is seen with average voltage and amplitude. Photic stimulation and hyperventilation was performed. Intermittent EMG artifacts were seen. Stage II sleep was not achieved.\n",
    "\n",
    "        IMPRESSION: This is an abnormal EEG with asymmetrical features there is delta wave slowing from right hemisphere. There are some faster frequencies on left side also that could be due to breach rhythm .kindly correlate clinically\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            response = ollama.chat(model='llama3.1', messages=[\n",
    "                {'role': 'system', 'content': system_instruction},\n",
    "                {'role': 'user', 'content': prompt_content},\n",
    "            ])\n",
    "            \n",
    "            report_text = response['message']['content']\n",
    "            \n",
    "            # Save to text file\n",
    "            out_file = os.path.join(REPORTS, folder, filename.replace('.edf', '.txt'))\n",
    "            with open(out_file, \"w\") as f:\n",
    "                f.write(report_text)\n",
    "                \n",
    "            print(f\"Saved report to: {out_file}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ollama Error: {e}\")\n",
    "\n",
    "        if device == 'cuda':\n",
    "            torch.cuda.empty_cache()\n",
    "        gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "GROUND_TRUTH_DIR = \"reports_extracted_txt\"  # Folder with real doctor reports\n",
    "GENERATED_DIR = \"reports_gen\"               # Folder with AI generated reports\n",
    "\n",
    "def load_file_pairs(gt_dir, gen_dir):\n",
    "    \"\"\"\n",
    "    Matches files in Ground Truth and Generated directories by filename.\n",
    "    Returns two lists: references (truth) and candidates (AI).\n",
    "    \"\"\"\n",
    "    refs = []\n",
    "    cands = []\n",
    "    matched_files = 0\n",
    "\n",
    "    print(f\"Scanning directories...\")\n",
    "    \n",
    "    # Walk through the Generated directory (since we only care about what we generated)\n",
    "    for root, dirs, files in os.walk(gen_dir):\n",
    "        for file in files:\n",
    "            if not file.endswith(\".txt\"):\n",
    "                continue\n",
    "            \n",
    "            # Path to the generated file\n",
    "            gen_path = os.path.join(root, file)\n",
    "            \n",
    "            # Construct the corresponding Ground Truth path\n",
    "            # Assuming structure matches (e.g., normal/file.txt)\n",
    "            rel_path = os.path.relpath(gen_path, gen_dir)\n",
    "            gt_path = os.path.join(gt_dir, rel_path)\n",
    "            \n",
    "            if os.path.exists(gt_path):\n",
    "                with open(gen_path, 'r', encoding='utf-8') as f:\n",
    "                    cands.append(f.read().strip())\n",
    "                \n",
    "                with open(gt_path, 'r', encoding='utf-8') as f:\n",
    "                    refs.append(f.read().strip())\n",
    "                \n",
    "                matched_files += 1\n",
    "            else:\n",
    "                # Optional: Warn if GT is missing for a generated file\n",
    "                # print(f\"Warning: No Ground Truth found for {rel_path}\")\n",
    "                pass\n",
    "\n",
    "    print(f\"Found {matched_files} matching report pairs.\")\n",
    "    return refs, cands\n",
    "\n",
    "def compute_metrics(references, candidates):\n",
    "    if not references:\n",
    "        print(\"No data to evaluate.\")\n",
    "        return\n",
    "\n",
    "    print(\"\\n--- Computing ROUGE-L ---\")\n",
    "    # Initialize ROUGE scorer (using 'rougeL' which accounts for sentence structure)\n",
    "    scorer = rouge_scorer.RougeScorer(['rougeL'], use_stemmer=True)\n",
    "    \n",
    "    rouge_l_f1s = []\n",
    "    rouge_l_precisions = []\n",
    "    rouge_l_recalls = []\n",
    "\n",
    "    for ref, cand in tqdm(zip(references, candidates), total=len(references)):\n",
    "        scores = scorer.score(ref, cand)\n",
    "        rouge_l_f1s.append(scores['rougeL'].fmeasure)\n",
    "        rouge_l_precisions.append(scores['rougeL'].precision)\n",
    "        rouge_l_recalls.append(scores['rougeL'].recall)\n",
    "\n",
    "    print(\"\\n--- Computing BERTScore (This may take a moment) ---\")\n",
    "    # BERTScore uses a pre-trained model to check semantic meaning\n",
    "    # 'distilbert-base-uncased' is faster; use 'roberta-large' for higher accuracy if you have GPU memory\n",
    "    P, R, F1 = score(candidates, references, lang=\"en\", verbose=True, model_type=\"distilbert-base-uncased\")\n",
    "\n",
    "    # --- PRINT RESULTS ---\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"FINAL EVALUATION RESULTS\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    print(f\"ROUGE-L F1:       {np.mean(rouge_l_f1s):.4f}\")\n",
    "    print(f\"ROUGE-L Precision:{np.mean(rouge_l_precisions):.4f}\")\n",
    "    print(f\"ROUGE-L Recall:   {np.mean(rouge_l_recalls):.4f}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"BERTScore F1:     {F1.mean().item():.4f}\")\n",
    "    print(f\"BERTScore Precision: {P.mean().item():.4f}\")\n",
    "    print(f\"BERTScore Recall:    {R.mean().item():.4f}\")\n",
    "    print(\"=\"*40)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1. Load Data\n",
    "    ground_truth_texts, generated_texts = load_file_pairs(GROUND_TRUTH_DIR, GENERATED_DIR)\n",
    "    \n",
    "    # 2. Run Evaluation\n",
    "    compute_metrics(ground_truth_texts, generated_texts)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "braindecode",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
